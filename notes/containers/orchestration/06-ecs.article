ECS and FARGATE for ECS
|| Last update: 21 Jan 2020

* Intro

NOTE: Most of these notes are taken from the AWS documentation on ecs.

ECS is a container management service region-specific.

* Cluster

A cluster is a logical grouping of resources (tasks and services).
If you run in ec2 lunch type, it will also include servers.
A cluster _can_ contain both ec2 and fargate workload.

** Events

- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_cwe_events.html]]

ECS sends state changes and publishes ECS Service Action events to Amazon
CloudWatch Events. CloudWatch Events delivers a near real-time stream of system
events that describe changes in AWS resources.

    [...] it is now possible to retrieve near real-time, event-driven updates
    on the state of your Amazon ECS tasks and container instances. Events are
    delivered through Amazon CloudWatch Events, and can be routed to any valid
    CloudWatch Events target, such as an AWS Lambda function or an Amazon SNS
    topic.
    Source: https://aws.amazon.com/about-aws/whats-new/2016/11/amazon-ec2-container-service-now-sends-state-changes-to-cloudwatch-events/

** EC2

A server running a container agent and registered to an cluster is called
_ecs_container_instance_.

EC2 instances can only be part of one cluster and you should never move them
between two cluster (always use new ones).

Container instance status are _active_, _inactive_ or _draining_.

*** The draining status

- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container-instance-draining.html]]

You can change the status of an instance to _draining_. When you do it, no new
tasks are assinged to the node, running tasks are moved if possible and no task
will be scheduled for replacement.

If resources are available, replacement services tasks are started on other
instances.

This functionality enables you to remove a container instance from a cluster
without impacting tasks.

*** The ECS agent

- [[https://github.com/aws/amazon-ecs-agent]]

The ecs agent will use the role of the node to authenticate. It will register,
deregister containers with the LBs.

The config file is at _/etc/ecs/ecs.config_.

The agent is able to clean unused disk space of docker (by default every 3h).
It checks/clean old/stopped containers.

An agent status is _true_ or _false_.

*** ECS optimised AMI

On the _ecs-optimised_ami_ the agent is already installed. You can hook yourself
to the bootstrap process via _user_data_.

On it there are also installed docker and a _nanny_process_ called *ecs-init* to
monitor the agent.

- [[https://github.com/aws/amazon-ecs-init]]

You can programmatically find the last optimised AMI via cli, sdk, CF or terraform.
They save this info on parameter store and you can retrieve it anytime.

The AMI ships with 30GB: 8GB are for root, _22GB_ for _docker_LVM_. You need to
use *lvm* commands to check the space.

Docker data volume is mounted under _/dev/xvdcz_.

To configure the docker deamon you need to use a _cloud-boothook_.

- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/bootstrap_container_instance.html#bootstrap_docker_daemon]]

Also look at _cloud_init_per_ tool.

- [[https://helpmanual.io/help/cloud-init-per/]]

You can use mime-multipart to join all them togheter.

Containers instances can be set to send logs to cloudwatch logs. However this
can be changed via _log_drivers_.

If you are using another image you will need to install the cloudwatch log agent.

** DELETING: Clean up

Load balancers need to be removed manually in a separated workflow in respect
of the ECS cluster.

- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_CleaningUp.html]]

NOTE: AWS advices to scale service tasks to 0 before deleting it.

* Workload types

You can define the number of tasks you want to run on the cluster in a service.
A *service* will run and maintain a specified number of tasks simultaneously.

A service can define two types of workload:

- REPLICA
- DEAMON

** Daemon

A *daemon* run a single instance of a task on every node of the cluster.
Usually this is very useful to run agents and management daemons (collect metrics,
clean up the node, watch for events and so on). This is similar to the concept
of _daemon_set_ in k8s. For obvious reasons fargate do not support this type of
workload.

* Tasks

A *task*definition* is in _json_ and containers up to _10_ containers.
It defines lunch type, ports, drives and so on.

A *task* is an instantiation of a task definition.

You can't move a task to another cluster.

** Launch types

There are two types of launch type:

- EC2: You create one or more ASG and attach it to the cluster
- Fargate: You just define the tasks but no cluster (costs much more)

*NOTE*: Many task definition parameters are _not_valid_ in fargate.

** SWAP

- [[https://aws.amazon.com/about-aws/whats-new/2019/08/amazon-ecs-now-supports-per-container-swap-space-parameters/]]

    With per-container swap configuration in ECS, customers can control each
    container's use of swap. Different containers can have swap enabled or
    disabled, and for those that have it enabled, the maximum amount of swap
    used can be limited per container. This means, for example, that latency-critical
    containers can have swap disabled, whereas containers with high transient
    memory demands can have swap turned on in order to reduce the likelihood of
    out-of-memory errors under load. ECS will ensure that each container runs
    with the desired swap configuration, even if those containers are running on
    the same EC2 instance.
    Source: https://aws.amazon.com/about-aws/whats-new/2019/08/amazon-ecs-now-supports-per-container-swap-space-parameters/

* Fargate for ECS

Some things to keep in consideration:

- Will require the network mode to be AWSVPC: you have no control on the host it sort of make sense that they don't allow host or bridge
- Will require to specify the the cpu and memory at task level while at container level is optional: in the end makes no sense since there is no cluster
- CPU and Memory are only allowed with specific values
- Only supports AWSLOGS and Splunk (from [[https://aws.amazon.com/about-aws/whats-new/2019/05/aws-fargate-pv1-3-now-supports-the-splunk-log-driver/][v1.3]]) as log drivers: since you can't install any other log drivers
- Doesn't allow EBS or EFS: since you can't install drivers or mount anything

Fargate has only 10GB of docker layer storage and 4GB for volume mounts to be
shared among containers.

** Multi-AZ

- [[https://forums.aws.amazon.com/thread.jspa?messageID=822753&tstart=0]]

You can't specify Placement constraints:

    Placement constraints are not supported with FARGATE launch type.

You implicitly provide the Availability Zone's as part of giving the subnets
for the service.

* Networking

You can launch a task with different Network configurations.

- none
- host
- bridge
- awsvpc

NOTE: User Defined Networks are not supported!

- [[https://github.com/aws/amazon-ecs-agent/issues/437][ISSUE #437 User Defined Networks]]
- [[https://medium.com/pablo-perez/ecs-service-discovery-to-work-around-lack-of-user-defined-bridge-network-ecs-limitation-6fa6b9672d84]]

AWS ECS Link is not bidirectional [[https://github.com/aws/amazon-ecs-agent/issues/1415]]
and docker link is deprecated.

** AWSVPC

- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-networking.html]]
- [[https://aws.amazon.com/blogs/compute/under-the-hood-task-networking-for-amazon-ecs/]]

.image images/cni-vpc.png _ 800
.caption Source: [[https://aws.amazon.com/blogs/compute/under-the-hood-task-networking-for-amazon-ecs/]]

When using _awsvpc_ you must specify one or more subnets and one or more sg to attach
to the ENI.

    To avoid the race condition between configuring the network stack and
    commands being invoked in application containers, the ECS agent creates an
    additional “pause” container for each task before starting the containers in
    the task definition. It then sets up the network namespace of the pause
    container by executing the previously mentioned CNI plugins. It also starts
    the rest of the containers in the task so that they share their network
    stack of the pause container. This means that all containers in a task are
    addressable by the IP addresses of the elastic network interface, and they
    can communicate with each other over the localhost interface.
    Source: https://aws.amazon.com/blogs/compute/under-the-hood-task-networking-for-amazon-ecs/

It *only*supports*A/NLB*. When creating a target group you need to use _ip_ as
target type and not instance. This is because you are targeting the ENI and not
the node. However you lose the ability of dynamic port mapping.

Each task will have it's own ENI.

Beware on finishing the allocation space for ENI.

- [[https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#AvailableIpPerENI]]
- [[https://github.com/aws/containers-roadmap/issues/7]]

A big constraints is the ENI limit per EC2 instance, the so-called ENI density
issue.

    The number of ENIs per instance is limited from 2 to 15 depending on the
    instance type. As EKS is sharing ENIs between pods, you can place up to 750
    pods per instance. Much more than the maximum of 15 tasks you can place per
    instance with ECS.
    Source: https://cloudonaut.io/eks-vs-ecs-orchestrating-containers-on-aws/

From June 2019 there is the option to raise the ENI density:

    Previously, Amazon ECS provisioned one ENI per task that used the awsvpc
    network mode. As a result, the number of ENIs available on EC2 instances
    often became the bounding constraint despite there being ample vCPU and
    memory available for additional containers to utilize. Now, you can enjoy
    increased ENI density limits that range anywhere from 3 to 8 times the
    number of ENIs previously available.
    Source: https://aws.amazon.com/about-aws/whats-new/2019/06/Amazon-ECS-Improves-ENI-Density-Limits-for-awsvpc-Networking-Mode/

** Internet access

If any of your container needs network access and is not running in mode awsvpc,
your server will need a public ip or a NAT.

If you need external access, you can map your network ports to a machine port
via bridge or host. The server sg *must* allow inbound access to the port you
want to expose.

* Namespaces

- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#other_container_definition_params]]

Two docker flags can be specified to share namespaces:

- pidMode: ontainers to share their process ID (PID) namespace with other containers in the task, or with the host
- ipcMode: containers to share their inter-process communication (IPC) namespace with the other containers in the task, or with the host

    Sharing the PID namespace enables for example monitoring applications
    deployed as containers to access information about other applications
    running in the same task or host.
    The IPC namespace allows containers to communicate directly through
    shared-memory with other containers running in the same task or host.
    Source: https://aws.amazon.com/about-aws/whats-new/2018/10/amazon-ecs-now-allows-two-additional-docker-flags-/

* Schedule workload

You can schedule based on resources, isolation and availability.

* Supported container registry

On fargate only ECR and dockerhub are supported. No other private container
registry.

* Secrets

- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data.html]]

You can specify secrets in ECS and for FARGATE from PV1.3.

* Monitoring

Abstractions are: tasks, services, and clusters

We have organized the metrics into two broad categories:

    Resource metrics, both at the level of ECS abstractions (tasks, services, and
    clusters) and at the level of containers and EC2 instances
    Metrics that track the current status of ECS tasks and services.
    Source: https://www.datadoghq.com/blog/amazon-ecs-metrics/

    Monitoring ECS involves paying attention to two levels of abstraction: the
    status of your services, tasks, and containers, as well as the resource use
    from the underlying compute and storage infrastructure, monitored per EC2 host
    or Docker container.
    [...]
    Note that CloudWatch does not surface metrics for the status of your
    services, tasks, or containers, so we’ll show you how to use the AWS CLI to
    query this information from the ECS API.
    Source: https://www.datadoghq.com/blog/ecs-monitoring-tools/

The CloudWatch console doesn’t include the sort of breakdowns of task status
you’d get from the ECS API.

    You’ll also find the desiredCount, runningCount, and pendingCount of tasks
    within each service, and the deployments array displays this information for
    each time you’ve launched a service.
    Source: https://www.datadoghq.com/blog/ecs-monitoring-tools/

To get this info you need to use the CLI.

In order to investigate ECS resource use at the container level, you’ll need
some way to query metrics from Docker itself.

    Consult our Docker monitoring guide to learn about three techniques for
    collecting Docker metrics: viewing pseudo-files in sysfs, running docker
    stats, and making calls to a local REST API that runs as part of the Docker
    daemon.
    Source: https://www.datadoghq.com/blog/ecs-monitoring-tools/

** Fargate metadata endpoint

    In order to collect metrics from Docker containers deployed with Fargate,
    you’ll need to query the ECS task metadata endpoint, a variation on the
    Docker API that runs on the ECS backend. If a container sends an HTTP
    request to the endpoint’s stats path, ECS will return, for each container
    in a task, the same JSON object you’d receive from a call to the stats
    endpoint of the Docker API. For version two of the ECS API, the IP address
    of the task metadata endpoint is static, and containers would send requests
    to 169.254.170.2/v2/stats. For version three, the URI of the endpoint is the
    value of the environment variable ECS_CONTAINER_METADATA_URI, which the ECS
    Agent defines automatically for each container in a task.
    [...]
    You can build a container image that queries the ECS task metadata endpoint
    automatically, setting the query script as its primary process. A single
    container within a task can request statistics for all of that task’s
    containers, so you simply need to name that container image within the
    task’s definition. The GitHub repository for the ECS Agent includes an
    example of such a script, written in Go (this script also queries the
    /metadata path, which returns basic information about a task, such as
    container names and task status).
    You can then configure your Fargate tasks to direct the output of your API
    calls to a destination of your choice, such as your CloudWatch logs (via
    awslogs).
    Source: https://www.datadoghq.com/blog/ecs-monitoring-tools/

* Enhanced Container Dependency management

- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#other_container_definition_params]]

    Enable defining dependencies for container startup and shutdown as well as a
    per-container start and stop timeout value.
    Source: Docs

Available on Fargate from PV 1.3.

* Problems

** User Defined Networks are not supported!

** Inability to mount configs

There is nothing like the kubernetes config maps and that makes mounting files
extremely difficult. EFS?

** Lack of task level metrics

    Having CPU/memory metrics per task allows us to debug task issues such as a
    hot task. We're able to isolate a task that might be in trouble and kill it
    before it introduces an issue. The cluster level metrics aren't helpful in
    many other cases.
    Source: [[https://github.com/aws/containers-roadmap/issues/70]]

- [[https://github.com/aws/containers-roadmap/issues/70]]

** Issue with cluster stabilising (~3h stabilizing)

    We have one stack stuck in UPDATE_ROLLBACK_IN_PROGRESS. The deployment of a
    new task/service failed and we CANCELLED the update. The stack went into
    UPDATE_ROLLBACK_IN_PROGRESS and never moved on.
    [...]
    We can't delete it it's just there. Please advice.

Reply:

    CloudFormation tries to ensure that all resources that it provisions are in
    a usable state to ensure there are no issues down the line. This is
    particularly important for eventually consistent resources. It seems that
    ECS service was waiting for getting the service stabilized, it waited for
    the default timeout of 3 hours (180 minutes) and finally moved to
    UPDATE_ROLLBACK_FAILED state. Now, since the stack is in
    UPDATE_ROLLBACK_FAILED state, you can go ahead and delete the stack.

Ways around it?

    Alternatively, you may choose to  skip the resource which is blocking the
    rollback and continue the update rollback to get the stack into an
    'UPDATE_ROLLBACK_COMPLETE' state from the UPDATE_ROLLBACK_FAILED' state.
    You can read more about it in the following link:
    http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-continueupdaterollback.html
    You could also attempt to continue the rollback using the
    'continue-update-rollback' CLI command as shown in the document given below:
    https://docs.aws.amazon.com/cli/latest/reference/cloudformation/continue-update-rollback.html

Basically:

    I do understand that it is a great inconvenience if the ECS service fails
    to get stabilized, it takes about 3 hours of time until you get a chance to
    make any further modifications on the stack. We already have a feature
    request for avoiding this situation as many customers raised this concern
    and Cloudformation service team is working on this issue. I have added +1
    on the internal ticket mentioning this case ID so that it can get more wait.

** Memory

    A task definition can also specify resource limits for the memory and CPU
    utilization of individual containers. Some parameters define impassable
    (“hard”) limits, while others define “soft” limits that can be ignored if
    resources are available. For example, the memory parameter always defines a
    hard limit, and ECS will terminate any container that crosses it, while the
    memoryReservation parameter always defines a soft limit.
    Source: https://www.datadoghq.com/blog/amazon-ecs-metrics/

* Re/Sources

- [[https://www.datadoghq.com/blog/amazon-ecs-metrics/]] - February 21, 2019
- [[https://www.datadoghq.com/blog/ecs-monitoring-tools/]] -  February 21, 2019
- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container-instance-draining.html]]
- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/bootstrap_container_instance.html#bootstrap_docker_daemon]]
- [[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_CleaningUp.html]]
