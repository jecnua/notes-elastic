ElasticSearch
|| Last update: 20 Jan 2021

* Intro

UPDATE: Elastic reply to AWS creating their own distro [[https://www.elastic.co/blog/on-open-distros-open-source-and-building-a-company]]

AWS articles:

- [[https://aws.amazon.com/blogs/aws/new-open-distro-for-elasticsearch/]]
- [[https://aws.amazon.com/blogs/opensource/keeping-open-source-open-open-distro-for-elasticsearch/]]

* Versions recap

[...]
6.2.0/6.2.4 April 2018
6.3.0/6.3.2 June 2018
    X-Pack features will now be bundled into the default distribution. All free features are included and enabled by default and will never ‘expire’, and commercial features are opt-in via a trial license. The license for free features never expires, you no longer need to register to use these capabilities.
    java 10
    Rolling upgrades from Elasticsearch 5.6.10 to 6.3.0 were broken when a synced flush was performed prior to upgrade. 6.3.1 includes the fix.
6.4.0/6.4.3 August 2018
6.5.0/6.5.4 Nov 2018
    Cross-cluster replication - a new, self-contained mechanism to replicate indices from one cluster to another
    Java 11 support
    G1 Garbage Collector (G1GC) is now supported by Elasticsearch
    Rollups support in Kibana includes a new management UI to configure and manage your rollup jobs, and the ability to visualize your rolled up indices in Kibana
    https://www.elastic.co/blog/elasticsearch-6-5-0-released
    Visualize infrastructure and logs https://www.elastic.co/blog/kibana-6-5-0-released
6.6.0/6.6.2 Jan 2019
    https://www.elastic.co/blog/elastic-stack-6-6-0-released
6.7.0/6.7.2 March 2019
    Cross cluster replication https://www.elastic.co/blog/elasticsearch-6-7-0-released
    Elasticsearch 6.7 is the Upgrade Release, meaning if you want to do a rolling upgrade from 6.x to 7.x, you will need to upgrade your cluster to 6.7.0 or higher first. Besides being the only 6.x release that will allow rolling upgrades to 7.x, Elasticsearch 6.7.0 comes with the latest deprecation logging to warn you about deprecated features you are using that will need to be replaced before migrating to 7.0. Even if you’re planning to do a full cluster restart to get to 7.x, we highly recommend first going to 6.7.0 or higher to look at the deprecation logs and ensure that your application is ready for the upgrade.
    upgrade API
    pluggable auth https://www.elastic.co/guide/en/elasticsearch/reference/6.7/custom-realms.html#using-custom-realm
    index lifecycle management https://www.elastic.co/blog/kibana-6-7-0-released
6.8.0/6.8.8
...
7.0.0/7.0.1 April 2019
    New lcuster coordination https://www.elastic.co/blog/elastic-stack-7-0-0-released
    default to 1 shard
    pre bundled jabva
    adaptive replica selection
NO 7.1.0/7.1.1 May 2019
    SECURITY IS FREE
7.2.0/7.2.1 June 2019
    SIEM
    Replicated close indices
7.3.0/7.3.2 July 2019
    removal of the minimum_master_nodes setting https://www.elastic.co/blog/a-new-era-for-cluster-coordination-in-elasticsearch
    gui have snapshot resgtore and retention
7.4.0/7.4.2 October 2019
    Snapshot lifecycle management
7.5.0/7.5.2 December 2019
    Snapshot lifecycle management retention
    Improvements to upgrades with Cross-Cluster Replication (CCR)
7.6.0/7.6.2 Feb 2020
    ILM users now have the ability to utilize a `wait_for_snapshot` action.
    Snapshots are now more efficient and faster to restore
    Snapshots are now more efficient and faster to restore
    With Elasticsearch 7.6, we've made major improvements to how snapshot metadata is stored within a snapshot repository to reduce API requests. Elasticsearch now uses cluster state to store pointers for valid snapshot metadata — saving on cloud provider requests and improving resiliency.
    We've also made snapshot restores faster by parallelizing restore operations for each shard.
    These enhancements to snapshot and restore are being released under the Apache 2.0 license.
    Proxy mode for cross-cluster replication and cross-cluster search

* Indices

For logging purposes the default of 5 shards per indices is too high. Many of the
indices you may have are probably less then a single gb a day and for sizes like
that 5 shards is overkill.

Aside from the performances issues of having too many shards for small indices
there is also the problem that you may soon reach the maximum amount of indices
you can have in a cluster.

While the max number of shards per node is a soft limit that can be raised,
having 1000 shards in a node (default) is already an horrible high limit.

To check how many shard do You have at the moment in the cluster use:

    $ GET /_stats
    [...]
    "_shards" : {
      "total" : 5000,
      "successful" : 5000,
      "failed" : 0
    },
    [...]

To see the historical data in prometheus, if you use the es exporter:

    elasticsearch_cluster_health_active_shards

Total cluster shard saturation (considering the default of 1000 per node was
not changed):

    (elasticsearch_cluster_health_active_shards / (elasticsearch_cluster_health_number_of_data_nodes * 1000)) * 100

To avoid this, set a default template with 1 shard and 1 replica per index
aside exceptions. To find your exceptions list all the indices you have in the
cluster than if you have anything that is more than 5gb without replica you may
think of sharding.

To create a default template you can do the following:

    PUT _template/dafault
    {
      "index_patterns": ["*"],
      "settings": {
        "number_of_shards": 1,
        "number_of_replicas": 1
      },
      "order" : 0
    }

Then you can put exceptions as needed:

    PUT _template/large-ind
    {
      "index_patterns": [
        "one-*",
        "two-*",
        "three-*"
      ],
      "settings": {
        "number_of_shards": 5,
        "number_of_replicas": 1
      },
      "order" : 1
    }

The “order” is important, so make sure the more specific indices are of higher
order than the default.

You can see the templates you have in the cluster with:

    # Kibana dev tool syntax
    GET _template

** Indices maintenance

* ILM and SLM

- [[https://www.elastic.co/guide/en/elasticsearch/reference/7.10/index-lifecycle-management.html]]
- [[https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshot-lifecycle-management.html]]

* Curator

** Helm chart

At the moment there is no usable curator chart available.
The old one is now deprecated:

- [[https://github.com/helm/charts/tree/master/stable/elasticsearch-curator]]

And Elastic have no intention to support curator (docker container or chart):

- [[https://github.com/elastic/helm-charts/issues/236]]
- [[https://github.com/elastic/helm-charts/pull/961]]

They are pushing instead for ILM and SLM which are very index-oriented and not
easily usable in a shared environment.

** Reduce shards of existing indices

If you are trying to reduce the shard pressure of an existing cluster when
indices have too many shards set by default, after creating the above templates
you can “shrink” the existing one.

Curator is able to do it via the shrink action:

- [[https://www.elastic.co/guide/en/elasticsearch/client/curator/current/shrink.html]]

    action: shrink
    description: >-
      Shrink selected indices on the node with the most available space.
      Delete source index after successful shrink, then reroute the shrunk
      index with the provided parameters.

Using this action, work on batches of indices (start from the older) and shrink
them to 1 shard and 1 replica. No data is lost during this process.
Don't make curator reindex all of them at the same time because curator can fail
for multiple reasons:

- if there is a snapshot running
- if there is something else happening in the cluster that impact the routing

Running it in batches and follow the process. When it fails (for example during
backup) you need to remove the "unfinished" new index and restart the process.
