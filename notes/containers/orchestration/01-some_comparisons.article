Some comparisons
|| Last update: 27 Sep 2018

* No namspaces on ECS

In ECS separation is both logical and physical
In k8s namespaces are logical separation into 'virtual clusters'

* Config configmaps

there is nothing like config-maps on ECS:

    Here it is worth noting the weakness of the ECS volumes feature compared to
    the numerous options in Kubernetes. In ECS you have to download any needed
    files to the ECS instance yourself if you want to make use of a docker
    volume mount with those files. These can be config files with options,
    templates needed by your containers, or secret credentials you have to
    inject during runtime. There are no options similar to what is available in
    Kubernetes, like a “Config Map” or “Secret” resource, which can be used as
    a volume mount later.

* ECS needs no master or control plane

That's a big pro.

* No sense to sidecar injection

ECS doesn't not have this concept

* No security divisions between namespaces

or workload

* no network ruling possible

same reason

* selection of nodes is limited in ECS

no concept of affinity, anti, tolerance, taints

* both have the concept of daemon set now

* Deployments are much more flexible in k8s

No concept of:

- service
- stateful Sept
- persistent volume claim

* Re/Sources

- [[https://kublr.com/blog/comparing-aws-ECS-and-self-managed-kubernetes-ECS-tutorial/]] - November 14, 2017
