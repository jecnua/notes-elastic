Jaeger
|| Last update: 14 May 2018

* Intro

.image images/Jaeger_Logo_Final_BLACK.png 400 _

My related code project [[https://github.com/jecnua/tracing-nodejs]].

* Jaeger

- [[http://www.jaegertracing.io/]]
- [[https://github.com/uber/jaeger]]
- [[https://github.com/cncf/toc/blob/master/proposals/jaeger.adoc]] CNCF proposal

    Low overhead, dynamic sampling, scalable

The backend is written in GO and the UI is in react.
Being pretty new, it's build to be scalable and it's cloud friendy. The client
emits the traces to the _agent_ which listen to spans (inbound) and route them
to the collector.

*Sponsorship*: Uber has 7 full time maintainers and Red Hat has 4 full time
maintainers

* Architecture

- [[https://www.jaegertracing.io/docs/architecture/]]

.image images/jaeger_arch.png 500 _
.caption Souce: [[https://www.jaegertracing.io/docs/architecture/]]

Jaeger was an uber project and has been build with scalability and parallelism in
mind.

** Workflow

.image images/jaeger_work.png 700 _
.caption Souce: [[https://www.jaegertracing.io/docs/architecture/]]


    The client emits traces to the agent which listens for inbound spans and routes
    them to the collector. The responsibility of the collector is to validate,
    transform and store the spans to the persistent storage. To access tracing data
    from the storage, the query service exposes a REST API endpoints and the React
    based UI.
    Source: https://sematext.com/blog/opentracing-jaeger-as-distributed-tracer/

** Agents

    $ [...] --collector.zipkin.http-port

The agents receive spans over UDP on port 5775. The spans are batched, encoded
as [[https://thrift.apache.org/][Thrift structures]] and submitted to the
collector.

*NOTE*: The app is using Thrift because at Uber was what they are used to.
However, it's in the planning a move to _gRPC_.
Source: https://groups.google.com/forum/#!topic/jaeger-tracing/toBNkL_zEDE

The Routing and Discovery phase of the collectors from the client library is also
the responsibility of the agent.

The agent *POLL* for a _sampling_strategy_ from the tracing backend and propagate
the sampling rate to all tracer clients. This is useful in dynamic environments.

Jaeger can accept Zipkin span transparently :D

** Span

Fields are:

- traceID
- spanID
- parentSpanID
- flags
- operationName
- references
- startTime (unix epoch)
- duration (millis)
- tags
- logs
- processID
- process
- serviceName
- warnings

** Storage

    $ jaeger-collector --span-storage.type elasticsearch [...]

It supports for _span_stores_:

- In-memory
- *Cassandra*
- *ElasticSearch*
- ScyllaDB (in progress)

In Elasticsearch two indices will be created: one for storing the services and
the other one for the spans of given services.

* Query API

Expose a rest interface.

* Sampling

For now they do not support tail-based sampling.
They allow:

- probabilist, head based sampling
- constant

- [[https://github.com/jaegertracing/jaeger/issues/425]] - Discuss post-trace (tail-based) sampling

* Test it

- [[https://github.com/jaegertracing/jaeger/tree/master/examples/hotrod]]

    docker run -d --name jaeger --rm -p 6831:6831/udp -p 16686:16686 jaegertracing/all-in-one:latest
    docker run --rm -it --link jaeger -p8080-8083:8080-8083 jaegertracing/example-hotrod:latest --jaeger-agent.host-port=jaeger:6831

If you want to sping the component separately:

- [[https://www.jaegertracing.io/docs/deployment/]]

** On k8s

- [[https://github.com/jaegertracing/jaeger-kubernetes]]

* Infrastructure

** Span context

The span context *is*NOT*defined* in the opentracing javascript

- [[https://github.com/opentracing/opentracing-javascript/blob/master/src/span_context.ts]]

* Monitoring

- [[https://www.jaegertracing.io/docs/monitoring/]]

Jeager export metrics via prometheus endpoint.

At Uber, they monitor:

- Node signals: CPU/memory usage, file descriptors, network usage, etc
- Go runtime signals: goroutine count, GC, etc
- Jaeger internals: dropped span count, mem queue size, storage write counts/latencies

At Uber they don't use auto-scaling for collectors, just a fixed size pool.
The bottleneck is typically the storage, which is hard to auto-scale.

* PRO and CON

Jaeger is newer in respect of Zipking, but allow dynamic sampling and has a lower
footprint.

* Roadmap

- [[https://www.jaegertracing.io/docs/roadmap/]]

* Re/Sources

- VIDEO [[https://www.youtube.com/watch?v=tFZAHWl8y_I][Jaeger Project Deep Dive - Juraci Kr√∂hling, Red Hat]] - 4 May 2018
- [[https://sematext.com/blog/opentracing-jaeger-as-distributed-tracer/]] - 8 May 2018
