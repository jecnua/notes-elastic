OPA, conftest and Gatekeeper
|| Last update: 2 Oct 2020

* Intro

Before going into this topic, please read more on admission controllers here:

- [[http://go-talks.appspot.com/github.com/jecnua/notes-presentations/notes/containers/orchestration/k8s/03-admission_controller.article][notes/containers/orchestration/k8s/03-admission_controller]]

* OPA

- [[https://www.openpolicyagent.org/]]

OPA is an open source, general-purpose policy engine.
OPA works on json, so if you have a yaml like in the case of k8s objects, first transform it to json.


** Rego

- [[https://play.openpolicyagent.org/]]

Rego is a DSL that allows to run assertions over structural data (but is not a
general purpose language). You can think of it as defensive programming.
Rego is a language to validate json and the validation results are json documents
themselves.
Rego *IS* confusing.
Since in older versions there are different interpretation of the equal sign
depending on the context, please now use:

- == instead of = for equality
- := to assign

To understand the usage please look at this valid rule in rego:

    s {
        x := 16
        y := 17
        x > y
    }

The above returns {} (empty).

    s {
        x := 16
        y := 17
        x < y
    }

The above returns:

    {
        "s": true
    }

Rego doesn't have a concept of allow/deny, it just query and returns structural
data.
Each line in each rule will be analysed, line by line, until the lines are "true"
it goes on. If it finds a false it stops and the blocks exists.
ALL the lines are ANDed.

If all the lines are true, the rule will result as true. To return something
different from just "true", you can use return values:

    foo[msg] {
        x := 16
        y := 17
        x < y
        msg := "test"
    }

The reply is:

    {
        "foo": [
            "test"
        ]
    }

* Conftest

- [[https://conftest.dev]]
- [[https://github.com/open-policy-agent/conftest]]

Conftest uses Rego language from Open Policy Agent for writing policies.
However it adds some conventions on top of it.
It expects policies to be in a directory that you pass to the command line tool,
and it apply all the rules in the dir to the specified inputs.

conftest looks for specific rules (what we called blocks before):

- deny
- warn
- violation

conftest supports yaml.

    deny[msg] {
        x := 16
        y := 17
        x > y
        msg := "test"
    }

** Bundle rules

You can write policies and bundle then to be pushed to a registry:

    conftest pull
    conftest push

* Gatekeeper

- [[https://github.com/open-policy-agent/gatekeeper]]

Bring OPA to k8s in a k8s native way. Gatekeeper uses Rego to interpret the message from the admission controller.

There are two main components in gatekeeper:

- gatekeeper-audit
- gatekeeper-controller-manager

Audit analyse the cluster constantly and reports on its status in respect of defined rules. It does not enforce anything
but only shows violations.

At the moment gatekeeper can only be used as a validation webhook and not as a mutating one. However work is in the
backlog to change this. Provides CRDs to interact with it:

- ConstraintTemplate
- Constraint

There is also another resource called _validatingwebhookconfigurations.admissionregistration.k8s.io_:

        $ k get validatingwebhookconfigurations.admissionregistration.k8s.io
        NAME                                          WEBHOOKS   AGE
        gatekeeper-validating-webhook-configuration   2          16m

There is a webhook called _check-ignore-label.gatekeeper.sh_.

The namespace webhook fails closed in order to prevent users from adding an ignore-all-policy label to namespaces that
shouldn't have them.

That particular webhook is set to fail closed because allowing users to set arbitrary labels on namespaces runs the
risk of allowing users to exempt namespaces from the main Gatekeeper webhook altogether.

NOTE: The k8s docs are not correct. You need to call the rego functions violation and not deny!

OPA FAILS SILENTLY

** Constraint templates

- [[https://github.com/open-policy-agent/gatekeeper#constraint-templates]]

Policies can be loaded into Gatekeeper dynamically via ConfigMaps objects using the kube-mgmt sidecar container.
It enables to setup a policy and feed this policy some parameters or data during evaluation.
However is a DSL nested in DSL!

The constraint templates functionality let you define a new CRD on the fly to define a policy that then user can apply.
The policy can be defined in one place and used in another.

The metadata.name of the ConstraintTemplate becomes the "kind" to be used in constraint.

** Rules / Constraints

- [[https://github.com/open-policy-agent/gatekeeper#constraints]]

When defining a rule, you can restrict on what specifically apply this rule to.
Among the selection you can do you can restrict to which namespace to run
the tests and which to ignore.
To exclude a namespace you can use the *excludedNamespaces* keyword:

    apiVersion: constraints.gatekeeper.sh/v1beta1
    kind: K8sImageDigests
    metadata:
      name: container-image-must-have-digest
    spec:
      match:
        kinds:
          - apiGroups: [""]
            kinds: ["Pod"]
        excludedNamespaces:
          - kube-system

You could also exclude it via CLI, however at the moment the chart does not
allow it.

- [[https://github.com/open-policy-agent/gatekeeper/blob/469f747df5b97317d968a8cc4b7ef53437860b28/deploy/gatekeeper.yaml#L710]]

    - args:
      - --port=8443
      - --logtostderr
      - --exempt-namespace=gatekeeper-system
      - --operation=webhook

More on it on the design paper for the functionality:

- [[https://docs.google.com/document/d/1yHuXFs_HQL5N9yT9QVi6AMyflWPtZS4Pg-uXczdqgZ8/edit#heading=h.fucr2hxulv8c]]

** Audit results

- [[https://github.com/open-policy-agent/gatekeeper#audit]]

The results of the scan are saved inside the instance of the CRD constraints you
created in the template. Taking the example for the repo README it would be
inside:

    apiVersion: constraints.gatekeeper.sh/v1beta1
    kind: K8sRequiredLabels

    kubectl describe K8sRequiredLabels <your_instance_of_it>

By default the violation saved in the object are 20, but you can change it with:

    --constraint-violations-limit=<number>

What you need to be careful with this change is the resulting size of the
object. ETCD max size for an object is 1MB and in general the bigger it is the
more load you will put on ETCD/api-server.
Reducing the frequency of the audit can help lower this pressure.

** UI

I found only one app that shows graphically the status of the gatekeeper
violations and is:

- [[https://github.com/sighupio/gatekeeper-policy-manager]]

It's still in early development but the graphical representation of the
violations is invaluable.

** Gatekeeper libraries

There are some predefined libraries here:

- [[https://github.com/open-policy-agent/gatekeeper-library]]
- [[https://github.com/sighupio/fury-kubernetes-opa/tree/master/katalog/gatekeeper]]

Where they also created some OPA policies to implement PSP behaviour.

** Resource order

To create the templates and the rules we need two charts: one for templates and
one for rules. The reason of this choice instead of merging them into one is
that the rules users CRD created on the fly by Gatekeeper itself when the
templates are applied. If you try to apply them together, the apply will fail.

I didnâ€™t find any way to force ordering and wait in helm between the two
different types (this is actually a missing feature
[[https://github.com/helm/helm/issues/8439]]).

This means the have this two charts to apply in order:

- gk-templates
- gk-rules

** List rules

Since gatekeeper creates CRD on the fly is not easy to find a way to query which
rules are active on the cluster. The best way I found until now it to list all
the CRD and than get the instance of it:

    k get ConstraintTemplate | grep -v Name | \
      cut -f1 -d' ' | xargs -I {} kubectl get {}

* Real use cases

Often conftests and Gatekeeper are both used just in different part of the
pipeline.

conftest is used in the CICD to validate early for errors, while gatekeeper is
used on the k8s cluster to check if anything got through and blocking at the
last possible moment.

Use conftest in the CI pipeline for extra check before failing in the cluster.

* Re/Sources

- [[https://www.youtube.com/watch?v=ZJgaGJm9NJE][TGI Kubernetes 119: Gatekeeper and OPA]] 22 May 2020
