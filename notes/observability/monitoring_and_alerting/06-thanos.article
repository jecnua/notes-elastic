Thanos - [WIP]
|| Last update: 28 Nov 2019

* Intro

- [[https://thanos.io/]]
- [[https://github.com/thanos-io/thanos]]
- [[https://improbable.io/blog/thanos-prometheus-at-scale]]
- [[https://thanos.io/getting-started.md/]]

Created at improbable is a way to extend prometheus and have long term storage
in s3.

** Global query view

    Prometheus encourages a functional sharding approach. Even single Prometheus
    server provides enough scalability to free users from the complexity of
    horizontal sharding in virtually all use cases.
    Source: https://improbable.io/blog/thanos-prometheus-at-scale

    With Thanos, on the other hand, you can query and aggregate data from
    multiple Prometheus servers, because all of them are available from a single
    endpoint.
    Source: https://improbable.io/blog/thanos-prometheus-at-scale

You can run more than one query node (one per cluster??) not to have a POF.

* Historical data

    Prometheus 2.0 helps a lot in this area, as a total number of time series no
    longer impact overall server performance (See Fabian’s KubeCon keynote about
    Prometheus 2). Still, Prometheus stores metric data to its local disk. While
    highly-efficient data compression can get significant mileage out of a local
    SSD, there is ultimately a limit on how much historical data can be stored.
    Source: https://improbable.io/blog/thanos-prometheus-at-scale

* Downsampling

    The usual solution to that problem is called downsampling, a process of
    reducing the sampling rate of the signal. With downsampled data, we can
    “zoom out” to a larger time range and maintain the same number of samples,
    thus keeping queries responsive.
    Downsampling old data is an inevitable requirement of any long-term storage
    solution and is beyond the scope of vanilla Prometheus.
    Source: https://improbable.io/blog/thanos-prometheus-at-scale

* Architecture

- [[https://fosdem.org/2019/schedule/event/thanos_transforming_prometheus_to_a_global_scale_in_a_seven_simple_steps/]] - 3 Feb 2019

Thanos uses a system of sidecars. Sidecars are added a each prometheus node and
allow to communicate.

*NOTE*: The gossip protocol has been
[[https://thanos.io/proposals/201809_gossip-removal.md/][deprecated]] in 0.5.0!

The sidecar watch for new files being created by prometheus (all metrics in a
time-range) and upload in a storage system like s3.
You can then, optionally, reduce the retention of the prometheus node and keep
it light (basically becoming a scraper).

Part of the cluster is the *store*, a component that will read the data
from s3 and cache it. it exposes a store API and is treated like any other
sidecar.

    Store Gateway knows how to deal with the data format of the Prometheus storage
    engine. Through smart query planning and by only caching the necessary index
    parts of blocks, it can reduce complex queries to a minimal amount of HTTP
    range requests against files in the object storage. This way it can reduce
    the number of naive requests by four to six orders of magnitude and achieve
    response times that are, in the big picture, hard to distinguish from queries
    against data on a local SSD.
    Source: https://improbable.io/blog/thanos-prometheus-at-scale

Another component is the compactor, that will take the data from s3, compact it
(also doing downsampling) and push it to s3. It allows better performance.
This job can run as a cron. It is not necessary. This decrease latency.

    To produce downsampled data, the Compactor continuously aggregates series
    down to five minute and one hour resolutions. For each raw chunk, encoded
    with TSDB’s XOR compression, it stores different types of aggregations, e.g.
    min, max, or sum in a single block. This allows Querier to automatically
    choose the aggregate that is appropriate for a given PromQL query.
    Source: https://improbable.io/blog/thanos-prometheus-at-scale

* Components

- [[https://quay.io/repository/thanos/thanos?tab=info]]

.image images/thanos_components.jpg

- Sidecar: connects to Prometheus and exposes it for real time queries by the Query Gateway and/or upload its data to cloud storage for longer term usage
- Query Gateway: implements Prometheus API to aggregate data from the underlying components (such as Sidecar or Store Gateway)
- Store Gateway: exposes the content of a cloud storage
- Compactor: compacts and down-samples data stored in cloud storage
- Receiver: receives data from Prometheus remote-write WAL, exposes it and/or upload it to cloud storage
- Ruler: evaluates recording and alerting rules against data in Thanos for exposition and/or upload

** Sidecar

- [[https://thanos.io/components/sidecar.md/]]

NOTE: This is the only place where I found a guide on how to create the secret
[[http://polarpoint.io/index.php/2019/06/17/devops-global-monitoring-using-prometheus-and-thanos/]]

    [it] runs alongside each Prometheus container that together form a cluster.
    Instead of querying directly to the Prometheus (this is the official plural
    according to Prometheus) you query the Thanos Query component.
    Source: https://medium.com/uswitch-labs/making-prometheus-more-awesome-with-thanos-fbec8c6c28ad

You need to add a sidecar to each prometheus
you are adding a separate gprc service called store API on each sidecar
it is for matching the data
it access the Prometheus directly for local data
add a label to Prometheus called

    thanos-store-api=true

special service that will gather all the store api
a service that expose storeapi under same domain

add some flags to allow variable substitution and another container.

THANOS 0.3.0

now you can do rolling update because is safe

** Integration with alert manager

All metrics needs to be *unique* so:

    external_labels:
      replica: ${POD_NAME} # new

also alerting you need to remove uniqueness
to allow to alert manager to decouple alert

alert relabel configs
regex replica
action labeldrop

** Gateway

to access object in the object storage
you need a thanos gateway

expose store api
and need access to the storage

** Thanos compactor

does not expose any api
works on only one thing
and also downsampled

*** Manage space

When using s3 bucket make sure to use a lifecyle policy to manage the blocks.

you can add here the config to use the bucket.
You need to DISABLE the compaction when you use an external bucket because
you will have an external compaction.

thanos sidecar synchs all xx
prometheus generate a file every two hours
and it will synch every two hours

** Querier

querier is stateless

then you need to add the Querierusing the store api
you need to add a special servuce to select the label we added before
this app will be set to discover local store with the dnssrv
and then take some remote store via IP and PORT

queries have the decuplication button to not show all labels
in new one version 0.3.0 the added the stores page in which the show all the
stores they have access to. they have a min and max time

thanos ueries have the same api as prometheus

** Thanos ruler

metamonitoring is important
monitor your monitoring

** Service discovery

- [[https://thanos.io/service-discovery.md/]]

*NOTE*: The gossip protocol has been
[[https://thanos.io/proposals/201809_gossip-removal.md/][deprecated]] in
[[https://github.com/thanos-io/thanos/releases/tag/v0.5.0][0.5.0]]!

Three options are now available:

- Static Flags
- [[https://thanos.io/service-discovery.md/#file-service-discovery][File SD]]
- [[https://thanos.io/service-discovery.md/#dns-service-discovery][DNS SD]]

* Helm chart

- [[https://github.com/banzaicloud/banzai-charts/tree/master/thanos]]

There are three chart of interest to manage prometheus with thanos:

- [[https://github.com/helm/charts/tree/master/stable/prometheus-operator]] - USE THIS ONE
- [[https://github.com/coreos/prometheus-operator]] - DON'T USE
- [[https://github.com/coreos/kube-prometheus]] - ???
The correct prometheus operator chart to use it the one in charts/stable and
not the one on the coreos github account. The stable one is based on the one
from coreos.

Create a file called create thanos-test.yaml


The create the secret:

    kubectl create secret generic thanos-storage-config \
      --from-file=thanos.yaml=PATH_TO_FILE/thanos-test.yaml --namespace monitoring

And check:

    k get secrets thanos-storage-config -o jsonpath='{.data.thanos\.yaml}' | base64 --decode

Now add the file to the prometheus operator:

    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#thanosspec
    thanos:         # add Thanos Sidecar
      image: quay.io/thanos/thanos:v0.7.0
      # version:
      # tag: v0.6.0
      # sha:
      # resource:
      objectStorageConfig: # blob storage to upload metrics
        key: thanos.yaml
        name: thanos-storage-config

NOTE: Beware. When you are no using dockerhub you can't use _tag_. Define the
version in the image line itself.

The real important piece of information here is the config file.

Inside the prometheus pod you will find now new file on disk:

    -rw-rw-r--    1 1000     2000         20001 Sep 16 10:44 queries.active
    drwxr-sr-x    3 1000     2000          4096 Sep 16 10:01 thanos
    -rw-r--r--    1 1000     2000            68 Sep 16 10:46 thanos.shipper.json
    drwxrwsr-x    4 1000     2000          4096 Sep 16 10:35 wal

And:

    /prometheus $ cat thanos.shipper.json
    {
            "version": 1,
            "uploaded": [
                    "01DMWMSNS0KTRM2HEQEKPY18HH"
            ]
    }

** PROB 1: Be aware of the Prometheus compactor

If you are adding Thanos to an existing prometheus the sidecar won't pick up the
old compacted data.

- [[https://github.com/thanos-io/thanos/issues/206][GITHUB ISSUE sidecar: Allow Thanos backup when local compaction is enabled]]

    Early on we hardcoded the sidecar to only upload blocks of comapction level
    0, i.e. those that never got compacted.
    With the garbage collection behavior the compactor has nowadays, it should
    be safe though to also upload historic data and potentially double-upload
    some data without lasting consequences. Just didn't get to changing the
    bahavior yet.
    Source: https://github.com/thanos-io/thanos/issues/206

You will need to edit the sidecar flags and add:

    --shipper.upload-compacted
    Source: https://github.com/thanos-io/thanos/issues/348#issuecomment-524289341

This is not written anywhere.
After it finished

    /prometheus $ ls -la  | grep 01D | grep -av '.tmp'
    drwxrwsr-x    3 1000     2000          4096 Sep  6 15:05 01DM3HNZ4101MQXD9D01ACHWZ3
    drwxrwsr-x    3 1000     2000          4096 Sep  7 09:59 01DM5JHHB4X62BRSJGM7VRCKV0
    drwxrwsr-x    3 1000     2000          4096 Sep  8 03:01 01DM7D1B3BD2GMW7R453PRTK5E
    drwxrwsr-x    3 1000     2000          4096 Sep  8 21:00 01DM9ATTQZWGCF7NKHNMA5PFG7
    drwxrwsr-x    3 1000     2000          4096 Sep  9 15:00 01DMB8MHDSQJ04NG726Q0WRFD1
    drwxrwsr-x    3 1000     2000          4096 Sep 10 09:00 01DMD6E0HA8Q062BGK6WXP9SWY
    drwxrwsr-x    3 1000     2000          4096 Sep 11 03:00 01DMF47GTP9EC7N7MNXRX8NYTM
    drwxrwsr-x    3 1000     2000          4096 Sep 11 21:00 01DMH2147ARS1AQ38J60F9EPVM
    drwxrwsr-x    3 1000     2000          4096 Sep 12 15:00 01DMJZTQB457QKN4KH3K3A30D4
    drwxrwsr-x    3 1000     2000          4096 Sep 13 09:00 01DMMXM5XSMP3V4JP06DE631E0
    drwxrwsr-x    3 1000     2000          4096 Sep 14 03:00 01DMPVDQJAZ3BQW0PAAZ30D9SQ
    drwxrwsr-x    3 1000     2000          4096 Sep 14 21:00 01DMRS78ECMKEWT368PSW47ZQZ
    drwxrwsr-x    3 1000     2000          4096 Sep 15 15:00 01DMTQ0SYD8RX0PBPXQPMP8JV4
    drwxrwsr-x    3 1000     2000          4096 Sep 16 09:00 01DMWMSNS0KTRM2HEQEKPY18HH
    drwxrwsr-x    3 1000     2000          4096 Sep 16 10:51 01DMWMTB37C5N1JK666FX05V1E
    drwxrwsr-x    3 1000     2000          4096 Sep 16 11:00 01DMWVND10T5K7Y6NHWT3V0T95
    /prometheus $ ls -la  | grep 01D | grep -av '.tmp' | wc -l
    16

And you see the right number of elements on s3, you can remove the flag.

next add banzaicloud to your repo:

    - name: banzaicloud-stable
      url: https://kubernetes-charts.banzaicloud.com

Exemple of something that does nothing!

      image:
        repository: quay.io/thanos/thanos
        tag: v0.7.0
      store:
        enabled: false
      query:
        enabled: false
      compact:
        enabled: false
      bucket:
        enabled: false
      sidecar:
        enabled: false
      objstore:
        type: s3
        config:
          bucket: prometheus-data-thanos-dev
          endpoint: s3.eu-west-1.amazonaws.com

You can use the thanos service in the chart to point to the operator.

Add sidecar to the other container

You will need to disable prometheus compaction before adding the sidecar with
shipping functionality:

    # In the prometheus chart (not operator)
    # Disable compaction
    extraArgs:
      storage.tsdb.min-block-duration: 2h
      storage.tsdb.max-block-duration: 2h

The best value is *2h*.

- [[https://github.com/coreos/prometheus-operator/issues/2196]]
- [[https://github.com/coreos/prometheus-operator/issues/1375]]

This example is obsolete:

- [[https://github.com/thanos-io/thanos/tree/master/tutorials/kubernetes-helm]]


- [[https://github.com/helm/charts/blob/c7e31361a28a10e30b4143b73439080d5e9f7d8b/stable/prometheus/templates/server-deployment.yaml#L138]]

    server:
      sidecarContainers:
        - args:
          - sidecar
          - --prometheus.url=http://127.0.0.1:9090/
          - --tsdb.path=/prometheus
          - --grpc-address=[$(POD_IP)]:10901
          - "--objstore.config={type: s3, config: {bucket: xyz, endpoint: s3.eu-west-1.amazonaws.com}}"
          - --log.level=debug
          - --log.format=logfmt
          - --shipper.upload-compacted # DISABLE PROMETHEUS COMPACTOR FIRST
          env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          image: quay.io/thanos/thanos:v0.7.0
          imagePullPolicy: IfNotPresent
          name: thanos-sidecar
          ports:
          - containerPort: 10902
            name: http
            protocol: TCP
          - containerPort: 10901
            name: grpc
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /prometheus
            name: storage-volume

BE CAREFUL OF THE VOLUME WHERE THE DATA IS.

NOTE: If you not disable the compactor you give you an error:

- [[https://github.com/thanos-io/thanos/blob/a07e91e05583a5002118f243d3f69a26f7035939/cmd/thanos/sidecar.go#L55]]

known issue: store after the compactor runs did not see old historical data! restart it

- [[https://github.com/thanos-io/thanos/issues/1492]]
- [[https://github.com/thanos-io/thanos/issues/631]]

.image images/thanos_ha.png


** PROB 2: Labels

- [[https://github.com/thanos-io/thanos/blob/973876f170032ecd38e2ac88f05ab38e5ed7f78b/docs/getting-started.md#external-labels]]

    Every Prometheus instance must have a globally unique set of identifying labels.
    Source: https://github.com/thanos-io/thanos/blob/973876f170032ecd38e2ac88f05ab38e5ed7f78b/docs/getting-started.md#external-labels

If you don't the sidecar will reject Prometheus servers without any external
labels all together. Otherwise you will see this:

    prometheus-server-7764c6fb85-x9gzz thanos-sidecar level=error ts=xxx
    caller=main.go:213 msg="running command failed" err="no external labels
    configured on Prometheus server, uniquely identifying external labels must
    be configured"

Add global labels

    serverFiles:
      prometheus.yml:
        global:
          external_labels:
            environment: {{ .Environment.Values | getOrNil "envname" | default "UNDEFINED" }}
            region: {{ .Environment.Values | getOrNil "region" | default "UNDEFINED" }}
            cluster: {{ .Environment.Values | getOrNil "cluster" | default "UNDEFINED" }}
            account: {{ .Environment.Values | getOrNil "account" | default "UNDEFINED" }}

** Process to move from old Prometheus

- create thanos secret manually with bucket (for now manually)
- create a prometheus operator instance with sidecar
- install thanos components: enable all BUT NOT COMPACTOR

- add sidecar to existing prometheus
- upload all data (also old with flag)
- redeploy without flag

* Thanos and Istio

- [[https://github.com/coreos/prometheus-operator/issues/2435]]

When you run prometheus operator with thanos and istio sidecar the thanos app
will fail to connect to prometheus.
The reason is that the argument generated by prometheus-operator for thanos sidecar
is:

    --grpc-address=[$(POD_IP)]:10901

So it binds to the pod ip. However istio forwards traffic to localhost.

- [[https://github.com/coreos/prometheus-operator/pull/2728]]
- [[https://github.com/coreos/prometheus-operator/pull/2728/files]]

There is a solution however. You can set `ListenLocal` on the Thanos spec and
this will solve the problem of Istio's forwarding of traffic to localhost.


  | listenLocal | ListenLocal makes the Thanos sidecar listen on loopback, so
  that it does not bind against the Pod IP. | bool | false |

- [[https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#thanosspec]]
- [[https://github.com/helm/charts/blob/master/stable/prometheus-operator/values.yaml]]

I still don't test this approach however.

* Re/Sources

- [[https://medium.com/uswitch-labs/making-prometheus-more-awesome-with-thanos-fbec8c6c28ad]] - 21 Nov 2018
- [[https://github.com/AICoE/prometheus-anomaly-detector]]
